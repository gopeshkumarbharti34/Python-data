{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library of Gaussian Naive Bayes Model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3  1  1 -2 -4 -1 -2]\n",
      "[3 1 7 1 7]\n"
     ]
    }
   ],
   "source": [
    "# assigning predictor and target values \n",
    "x=np.array([[-3,7],[1,5],[1,2],[-2,0],[2,3],[-4,0],[-1,1],[1,1],[-2,2],[2,7],[-4,1],[-2,7]])\n",
    "y=np.array([1,1,1,1,2,1,1,2,1,2,2,2])\n",
    "x1=np.array([[-3,7],[1,5],[1,2],[-2,0],[-4,0],[-1,1],[-2,2]])\n",
    "x2=np.array([[2,3],[1,1],[2,7],[-4,1],[-2,7]])\n",
    "\n",
    "print(x1[...,0])\n",
    "print(x2[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3c33b88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x1[...,0],x1[...,1],'ob',label='Type-1')\n",
    "plt.plot(x2[...,0],x2[...,1],'vk',label='Type-2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Gaussian Classifier\n",
    "model=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets \n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GaussianNB in module sklearn.naive_bayes:\n",
      "\n",
      "class GaussianNB(BaseNB)\n",
      " |  Gaussian Naive Bayes (GaussianNB)\n",
      " |  \n",
      " |  Can perform online updates to model parameters via `partial_fit` method.\n",
      " |  For details on algorithm used to update feature means and variance online,\n",
      " |  see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
      " |  \n",
      " |      http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gaussian_naive_bayes>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  priors : array-like, shape (n_classes,)\n",
      " |      Prior probabilities of the classes. If specified the priors are not\n",
      " |      adjusted according to the data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_prior_ : array, shape (n_classes,)\n",
      " |      probability of each class.\n",
      " |  \n",
      " |  class_count_ : array, shape (n_classes,)\n",
      " |      number of training samples observed in each class.\n",
      " |  \n",
      " |  theta_ : array, shape (n_classes, n_features)\n",
      " |      mean of each feature per class\n",
      " |  \n",
      " |  sigma_ : array, shape (n_classes, n_features)\n",
      " |      variance of each feature per class\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      " |  >>> Y = np.array([1, 1, 1, 2, 2, 2])\n",
      " |  >>> from sklearn.naive_bayes import GaussianNB\n",
      " |  >>> clf = GaussianNB()\n",
      " |  >>> clf.fit(X, Y)\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  >>> clf_pf = GaussianNB()\n",
      " |  >>> clf_pf.partial_fit(X, Y, np.unique(Y))\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf_pf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GaussianNB\n",
      " |      BaseNB\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, priors=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Gaussian Naive Bayes according to X, y\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      " |      Incremental fit on a batch of samples.\n",
      " |      \n",
      " |      This method is expected to be called several times consecutively\n",
      " |      on different chunks of a dataset so as to implement out-of-core\n",
      " |      or online learning.\n",
      " |      \n",
      " |      This is especially useful when the whole dataset is too big to fit in\n",
      " |      memory at once.\n",
      " |      \n",
      " |      This method has some performance and numerical stability overhead,\n",
      " |      hence it is better to call partial_fit on chunks of data that are\n",
      " |      as large as possible (as long as fitting in the memory budget) to\n",
      " |      hide the overhead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      classes : array-like, shape (n_classes,), optional (default=None)\n",
      " |          List of all the classes that can possibly appear in the y vector.\n",
      " |      \n",
      " |          Must be provided at the first call to partial_fit, can be omitted\n",
      " |          in subsequent calls.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseNB:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on an array of test vectors X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted target values for X\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return log-probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Predict Output\n",
    "test_data=np.array([[0,2],[3,4],[-3,6],[1,6],[-4,0.5]])\n",
    "predicted=model.predict(test_data)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80000000000000004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class=[1,2,2,2,1]\n",
    "model.score(test_data,actual_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3c3e66080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x1[...,0],x1[...,1],'ob',label='Type-1')\n",
    "plt.plot(x2[...,0],x2[...,1],'vk',label='Type-2')\n",
    "plt.plot(test_data[...,0],test_data[...,1],'xr',label='To Predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Regression \n",
    "## Continious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets ## Imports data sets from scikit learn \n",
    "data=datasets.load_boston() ## Loads Bostan Datasets from datasets library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "print(data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
      "          1.53000000e+01,   3.96900000e+02,   4.98000000e+00],\n",
      "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
      "          1.78000000e+01,   3.96900000e+02,   9.14000000e+00],\n",
      "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
      "          1.78000000e+01,   3.92830000e+02,   4.03000000e+00],\n",
      "       ..., \n",
      "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
      "          2.10000000e+01,   3.96900000e+02,   5.64000000e+00],\n",
      "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
      "          2.10000000e+01,   3.93450000e+02,   6.48000000e+00],\n",
      "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
      "          2.10000000e+01,   3.96900000e+02,   7.88000000e+00]]), 'target': array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
      "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
      "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
      "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
      "        20. ,  21. ,  24.7,  30.8,  34.9,  26.6,  25.3,  24.7,  21.2,\n",
      "        19.3,  20. ,  16.6,  14.4,  19.4,  19.7,  20.5,  25. ,  23.4,\n",
      "        18.9,  35.4,  24.7,  31.6,  23.3,  19.6,  18.7,  16. ,  22.2,\n",
      "        25. ,  33. ,  23.5,  19.4,  22. ,  17.4,  20.9,  24.2,  21.7,\n",
      "        22.8,  23.4,  24.1,  21.4,  20. ,  20.8,  21.2,  20.3,  28. ,\n",
      "        23.9,  24.8,  22.9,  23.9,  26.6,  22.5,  22.2,  23.6,  28.7,\n",
      "        22.6,  22. ,  22.9,  25. ,  20.6,  28.4,  21.4,  38.7,  43.8,\n",
      "        33.2,  27.5,  26.5,  18.6,  19.3,  20.1,  19.5,  19.5,  20.4,\n",
      "        19.8,  19.4,  21.7,  22.8,  18.8,  18.7,  18.5,  18.3,  21.2,\n",
      "        19.2,  20.4,  19.3,  22. ,  20.3,  20.5,  17.3,  18.8,  21.4,\n",
      "        15.7,  16.2,  18. ,  14.3,  19.2,  19.6,  23. ,  18.4,  15.6,\n",
      "        18.1,  17.4,  17.1,  13.3,  17.8,  14. ,  14.4,  13.4,  15.6,\n",
      "        11.8,  13.8,  15.6,  14.6,  17.8,  15.4,  21.5,  19.6,  15.3,\n",
      "        19.4,  17. ,  15.6,  13.1,  41.3,  24.3,  23.3,  27. ,  50. ,\n",
      "        50. ,  50. ,  22.7,  25. ,  50. ,  23.8,  23.8,  22.3,  17.4,\n",
      "        19.1,  23.1,  23.6,  22.6,  29.4,  23.2,  24.6,  29.9,  37.2,\n",
      "        39.8,  36.2,  37.9,  32.5,  26.4,  29.6,  50. ,  32. ,  29.8,\n",
      "        34.9,  37. ,  30.5,  36.4,  31.1,  29.1,  50. ,  33.3,  30.3,\n",
      "        34.6,  34.9,  32.9,  24.1,  42.3,  48.5,  50. ,  22.6,  24.4,\n",
      "        22.5,  24.4,  20. ,  21.7,  19.3,  22.4,  28.1,  23.7,  25. ,\n",
      "        23.3,  28.7,  21.5,  23. ,  26.7,  21.7,  27.5,  30.1,  44.8,\n",
      "        50. ,  37.6,  31.6,  46.7,  31.5,  24.3,  31.7,  41.7,  48.3,\n",
      "        29. ,  24. ,  25.1,  31.5,  23.7,  23.3,  22. ,  20.1,  22.2,\n",
      "        23.7,  17.6,  18.5,  24.3,  20.5,  24.5,  26.2,  24.4,  24.8,\n",
      "        29.6,  42.8,  21.9,  20.9,  44. ,  50. ,  36. ,  30.1,  33.8,\n",
      "        43.1,  48.8,  31. ,  36.5,  22.8,  30.7,  50. ,  43.5,  20.7,\n",
      "        21.1,  25.2,  24.4,  35.2,  32.4,  32. ,  33.2,  33.1,  29.1,\n",
      "        35.1,  45.4,  35.4,  46. ,  50. ,  32.2,  22. ,  20.1,  23.2,\n",
      "        22.3,  24.8,  28.5,  37.3,  27.9,  23.9,  21.7,  28.6,  27.1,\n",
      "        20.3,  22.5,  29. ,  24.8,  22. ,  26.4,  33.1,  36.1,  28.4,\n",
      "        33.4,  28.2,  22.8,  20.3,  16.1,  22.1,  19.4,  21.6,  23.8,\n",
      "        16.2,  17.8,  19.8,  23.1,  21. ,  23.8,  23.1,  20.4,  18.5,\n",
      "        25. ,  24.6,  23. ,  22.2,  19.3,  22.6,  19.8,  17.1,  19.4,\n",
      "        22.2,  20.7,  21.1,  19.5,  18.5,  20.6,  19. ,  18.7,  32.7,\n",
      "        16.5,  23.9,  31.2,  17.5,  17.2,  23.1,  24.5,  26.6,  22.9,\n",
      "        24.1,  18.6,  30.1,  18.2,  20.6,  17.8,  21.7,  22.7,  22.6,\n",
      "        25. ,  19.9,  20.8,  16.8,  21.9,  27.5,  21.9,  23.1,  50. ,\n",
      "        50. ,  50. ,  50. ,  50. ,  13.8,  13.8,  15. ,  13.9,  13.3,\n",
      "        13.1,  10.2,  10.4,  10.9,  11.3,  12.3,   8.8,   7.2,  10.5,\n",
      "         7.4,  10.2,  11.5,  15.1,  23.2,   9.7,  13.8,  12.7,  13.1,\n",
      "        12.5,   8.5,   5. ,   6.3,   5.6,   7.2,  12.1,   8.3,   8.5,\n",
      "         5. ,  11.9,  27.9,  17.2,  27.5,  15. ,  17.2,  17.9,  16.3,\n",
      "         7. ,   7.2,   7.5,  10.4,   8.8,   8.4,  16.7,  14.2,  20.8,\n",
      "        13.4,  11.7,   8.3,  10.2,  10.9,  11. ,   9.5,  14.5,  14.1,\n",
      "        16.1,  14.3,  11.7,  13.4,   9.6,   8.7,   8.4,  12.8,  10.5,\n",
      "        17.1,  18.4,  15.4,  10.8,  11.8,  14.9,  12.6,  14.1,  13. ,\n",
      "        13.4,  15.2,  16.1,  17.8,  14.9,  14.1,  12.7,  13.5,  14.9,\n",
      "        20. ,  16.4,  17.7,  19.5,  20.2,  21.4,  19.9,  19. ,  19.1,\n",
      "        19.1,  20.1,  19.9,  19.6,  23.2,  29.8,  13.8,  13.3,  16.7,\n",
      "        12. ,  14.6,  21.4,  23. ,  23.7,  25. ,  21.8,  20.6,  21.2,\n",
      "        19.1,  20.6,  15.2,   7. ,   8.1,  13.6,  20.1,  21.8,  24.5,\n",
      "        23.1,  19.7,  18.3,  21.2,  17.5,  16.8,  22.4,  20.6,  23.9,\n",
      "        22. ,  11.9]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
      "       'TAX', 'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='<U7'), 'DESCR': \"Boston House Prices dataset\\n===========================\\n\\nNotes\\n------\\nData Set Characteristics:  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive\\n    \\n    :Median Value (attribute 14) is usually the target\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttp://archive.ics.uci.edu/ml/datasets/Housing\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n**References**\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\\n\"}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#defines the data / predictors as the pre sets features names \n",
    "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "\n",
    "\n",
    "# put the target (housing value--MEDV) in another DataFrame\n",
    "target =pd.DataFrame(data.target,columns=['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
      "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
      "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
      "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
      "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "501     21.0  391.99   9.67  \n",
      "502     21.0  396.90   9.08  \n",
      "503     21.0  396.90   5.64  \n",
      "504     21.0  393.45   6.48  \n",
      "505     21.0  396.90   7.88  \n",
      "     MEDV\n",
      "501  22.4\n",
      "502  20.6\n",
      "503  23.9\n",
      "504  22.0\n",
      "505  11.9\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())\n",
    "print(target.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Bunch in module sklearn.utils object:\n",
      "\n",
      "class Bunch(builtins.dict)\n",
      " |  Container object for datasets\n",
      " |  \n",
      " |  Dictionary-like object that exposes its keys as attributes.\n",
      " |  \n",
      " |  >>> b = Bunch(a=1, b=2)\n",
      " |  >>> b['b']\n",
      " |  2\n",
      " |  >>> b.b\n",
      " |  2\n",
      " |  >>> b.a = 3\n",
      " |  >>> b['a']\n",
      " |  3\n",
      " |  >>> b.c = 6\n",
      " |  >>> b['c']\n",
      " |  6\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Bunch\n",
      " |      builtins.dict\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, key)\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __setattr__(self, key, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from builtins.dict:\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      True if D has a key k, else False.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(...)\n",
      " |      x.__getitem__(y) <==> x[y]\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setitem__(self, key, value, /)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -> size of D in memory, in bytes\n",
      " |  \n",
      " |  clear(...)\n",
      " |      D.clear() -> None.  Remove all items from D.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      D.copy() -> a shallow copy of D\n",
      " |  \n",
      " |  fromkeys(iterable, value=None, /) from builtins.type\n",
      " |      Returns a new dict with keys from iterable and values equal to value.\n",
      " |  \n",
      " |  get(...)\n",
      " |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      " |  \n",
      " |  items(...)\n",
      " |      D.items() -> a set-like object providing a view on D's items\n",
      " |  \n",
      " |  keys(...)\n",
      " |      D.keys() -> a set-like object providing a view on D's keys\n",
      " |  \n",
      " |  pop(...)\n",
      " |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      " |      If key is not found, d is returned if given, otherwise KeyError is raised\n",
      " |  \n",
      " |  popitem(...)\n",
      " |      D.popitem() -> (k, v), remove and return some (key, value) pair as a\n",
      " |      2-tuple; but raise KeyError if D is empty.\n",
      " |  \n",
      " |  setdefault(...)\n",
      " |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      " |  \n",
      " |  update(...)\n",
      " |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\n",
      " |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\n",
      " |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\n",
      " |      In either case, this is followed by: for k in F:  D[k] = F[k]\n",
      " |  \n",
      " |  values(...)\n",
      " |      D.values() -> an object providing a view on D's values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from builtins.dict:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
      "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
      "1     0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n",
      "2     0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n",
      "3     0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n",
      "4     0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n",
      "5     0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n",
      "6     0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n",
      "7     0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n",
      "8     0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
      "9     0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n",
      "10    0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n",
      "11    0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n",
      "12    0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n",
      "13    0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n",
      "14    0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n",
      "15    0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n",
      "16    1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n",
      "17    0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
      "18    0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n",
      "19    0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n",
      "20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
      "21    0.85204   0.0   8.14   0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n",
      "22    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
      "23    0.98843   0.0   8.14   0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n",
      "24    0.75026   0.0   8.14   0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
      "25    0.84054   0.0   8.14   0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n",
      "26    0.67191   0.0   8.14   0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
      "27    0.95577   0.0   8.14   0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n",
      "28    0.77299   0.0   8.14   0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n",
      "29    1.00245   0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n",
      "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
      "476   4.87141   0.0  18.10   0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n",
      "477  15.02340   0.0  18.10   0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n",
      "478  10.23300   0.0  18.10   0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n",
      "479  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
      "480   5.82401   0.0  18.10   0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n",
      "481   5.70818   0.0  18.10   0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n",
      "482   5.73116   0.0  18.10   0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n",
      "483   2.81838   0.0  18.10   0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
      "484   2.37857   0.0  18.10   0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
      "485   3.67367   0.0  18.10   0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n",
      "486   5.69175   0.0  18.10   0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n",
      "487   4.83567   0.0  18.10   0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n",
      "488   0.15086   0.0  27.74   0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n",
      "489   0.18337   0.0  27.74   0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n",
      "490   0.20746   0.0  27.74   0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n",
      "491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
      "492   0.11132   0.0  27.74   0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n",
      "493   0.17331   0.0   9.69   0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
      "494   0.27957   0.0   9.69   0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n",
      "495   0.17899   0.0   9.69   0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n",
      "496   0.28960   0.0   9.69   0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n",
      "497   0.26838   0.0   9.69   0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n",
      "498   0.23912   0.0   9.69   0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n",
      "499   0.17783   0.0   9.69   0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n",
      "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
      "501   0.06263   0.0  11.93   0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n",
      "502   0.04527   0.0  11.93   0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n",
      "503   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
      "504   0.10959   0.0  11.93   0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n",
      "505   0.04741   0.0  11.93   0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "0       15.3  396.90   4.98  \n",
      "1       17.8  396.90   9.14  \n",
      "2       17.8  392.83   4.03  \n",
      "3       18.7  394.63   2.94  \n",
      "4       18.7  396.90   5.33  \n",
      "5       18.7  394.12   5.21  \n",
      "6       15.2  395.60  12.43  \n",
      "7       15.2  396.90  19.15  \n",
      "8       15.2  386.63  29.93  \n",
      "9       15.2  386.71  17.10  \n",
      "10      15.2  392.52  20.45  \n",
      "11      15.2  396.90  13.27  \n",
      "12      15.2  390.50  15.71  \n",
      "13      21.0  396.90   8.26  \n",
      "14      21.0  380.02  10.26  \n",
      "15      21.0  395.62   8.47  \n",
      "16      21.0  386.85   6.58  \n",
      "17      21.0  386.75  14.67  \n",
      "18      21.0  288.99  11.69  \n",
      "19      21.0  390.95  11.28  \n",
      "20      21.0  376.57  21.02  \n",
      "21      21.0  392.53  13.83  \n",
      "22      21.0  396.90  18.72  \n",
      "23      21.0  394.54  19.88  \n",
      "24      21.0  394.33  16.30  \n",
      "25      21.0  303.42  16.51  \n",
      "26      21.0  376.88  14.81  \n",
      "27      21.0  306.38  17.28  \n",
      "28      21.0  387.94  12.80  \n",
      "29      21.0  380.23  11.98  \n",
      "..       ...     ...    ...  \n",
      "476     20.2  396.21  18.68  \n",
      "477     20.2  349.48  24.91  \n",
      "478     20.2  379.70  18.03  \n",
      "479     20.2  383.32  13.11  \n",
      "480     20.2  396.90  10.74  \n",
      "481     20.2  393.07   7.74  \n",
      "482     20.2  395.28   7.01  \n",
      "483     20.2  392.92  10.42  \n",
      "484     20.2  370.73  13.34  \n",
      "485     20.2  388.62  10.58  \n",
      "486     20.2  392.68  14.98  \n",
      "487     20.2  388.22  11.45  \n",
      "488     20.1  395.09  18.06  \n",
      "489     20.1  344.05  23.97  \n",
      "490     20.1  318.43  29.68  \n",
      "491     20.1  390.11  18.07  \n",
      "492     20.1  396.90  13.35  \n",
      "493     19.2  396.90  12.01  \n",
      "494     19.2  396.90  13.59  \n",
      "495     19.2  393.29  17.60  \n",
      "496     19.2  396.90  21.14  \n",
      "497     19.2  396.90  14.10  \n",
      "498     19.2  396.90  12.92  \n",
      "499     19.2  395.77  15.10  \n",
      "500     19.2  396.90  14.33  \n",
      "501     21.0  391.99   9.67  \n",
      "502     21.0  396.90   9.08  \n",
      "503     21.0  396.90   5.64  \n",
      "504     21.0  393.45   6.48  \n",
      "505     21.0  396.90   7.88  \n",
      "\n",
      "[506 rows x 13 columns]\n",
      "     MEDV\n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n",
      "5    28.7\n",
      "6    22.9\n",
      "7    27.1\n",
      "8    16.5\n",
      "9    18.9\n",
      "10   15.0\n",
      "11   18.9\n",
      "12   21.7\n",
      "13   20.4\n",
      "14   18.2\n",
      "15   19.9\n",
      "16   23.1\n",
      "17   17.5\n",
      "18   20.2\n",
      "19   18.2\n",
      "20   13.6\n",
      "21   19.6\n",
      "22   15.2\n",
      "23   14.5\n",
      "24   15.6\n",
      "25   13.9\n",
      "26   16.6\n",
      "27   14.8\n",
      "28   18.4\n",
      "29   21.0\n",
      "..    ...\n",
      "476  16.7\n",
      "477  12.0\n",
      "478  14.6\n",
      "479  21.4\n",
      "480  23.0\n",
      "481  23.7\n",
      "482  25.0\n",
      "483  21.8\n",
      "484  20.6\n",
      "485  21.2\n",
      "486  19.1\n",
      "487  20.6\n",
      "488  15.2\n",
      "489   7.0\n",
      "490   8.1\n",
      "491  13.6\n",
      "492  20.1\n",
      "493  21.8\n",
      "494  24.5\n",
      "495  23.1\n",
      "496  19.7\n",
      "497  18.3\n",
      "498  21.2\n",
      "499  17.5\n",
      "500  16.8\n",
      "501  22.4\n",
      "502  20.6\n",
      "503  23.9\n",
      "504  22.0\n",
      "505  11.9\n",
      "\n",
      "[506 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "x=df\n",
    "y=target   #y=target['MEDV']\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm=linear_model.LinearRegression()\n",
    "lm.fit(x,y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.00821269]\n",
      " [ 25.0298606 ]\n",
      " [ 30.5702317 ]\n",
      " [ 28.60814055]\n",
      " [ 27.94288232]]\n",
      "   MEDV\n",
      "0  24.0\n",
      "1  21.6\n",
      "2  34.7\n",
      "3  33.4\n",
      "4  36.2\n"
     ]
    }
   ],
   "source": [
    "predictions=lm.predict(x[0:5])\n",
    "print(predictions)\n",
    "print(y[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406077428649428"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logical Regression \n",
    "### (for the Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.array([[-3,7],[1,5],[1,2],[-2,0],[2,3],[-4,0],[-1,1],[1,1],[-2,2],[2,7],[-4,1],[-2,7]])\n",
    "y=np.array([1,1,1,1,2,1,1,2,1,2,2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=LogisticRegression(random_state=0)\n",
    "classifier.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict([[1,2],[2,7]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8e03de7ba1f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "help(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
